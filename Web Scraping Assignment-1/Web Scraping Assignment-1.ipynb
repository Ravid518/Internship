{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc73e56b",
   "metadata": {},
   "source": [
    "Answer 1. Wikipedia Header Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f62dda85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeaderTag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main Page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       HeaderTag\n",
       "0                      Main Page\n",
       "1           Welcome to Wikipedia\n",
       "2  From today's featured article\n",
       "3               Did you know ...\n",
       "4                    In the news\n",
       "5                    On this day\n",
       "6       Today's featured picture\n",
       "7       Other areas of Wikipedia\n",
       "8    Wikipedia's sister projects\n",
       "9            Wikipedia languages"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Libraries \n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Get the HTML content of the Wikipedia.org homepage\n",
    "webpage = requests.get('https://en.wikipedia.org/wiki/Main_Page').content\n",
    "soup = BeautifulSoup(webpage, 'lxml')\n",
    "\n",
    "header=soup.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "HeaderTag = []\n",
    "for tag in header:\n",
    "    HeaderTag.append(tag.text)\n",
    "\n",
    "df=pd.DataFrame({'HeaderTag':HeaderTag})\n",
    "df                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1182937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82f39016",
   "metadata": {},
   "source": [
    "Answer 2. IMDB Top 50 Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e3b24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>Year_of_release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>9</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La vita è bella</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Il buono, il brutto, il cattivo</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Pursuit of Happyness</td>\n",
       "      <td>8</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shichinin no samurai</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1954)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Central do Brasil</td>\n",
       "      <td>8</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Requiem for a Dream</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A Beautiful Mind</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hachi: A Dog's Tale</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Taken</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(I) (2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Yeopgijeogin geunyeo</td>\n",
       "      <td>8</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Amores perros</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Shining</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Apocalypto</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gladiator</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cast Away</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The Pianist</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>7.9</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Bin-jip</td>\n",
       "      <td>7.9</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Braveheart</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>It's a Wonderful Life</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1946)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bom yeoreum gaeul gyeoul geurigo bom</td>\n",
       "      <td>8</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Alien</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Salinui chueok</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Vozvrashchenie</td>\n",
       "      <td>7.9</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Ang-ma-reul bo-at-da</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Bacheha-Ye aseman</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Jodaeiye Nader az Simin</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>The Sixth Sense</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Nae meorisokui jiwoogae</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Okuribito</td>\n",
       "      <td>8</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Wo de fu qin mu qin</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The Bridge on the River Kwai</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Ben-Hur</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The Exorcist</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1973)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>El secreto de sus ojos</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Léon</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>The Green Mile</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Gran Torino</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Kill Bill: Vol. 1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Jurassic Park</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Back to the Future</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Finding Nemo</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name rating Year_of_release\n",
       "0                          The Godfather    9.2          (1972)\n",
       "1                       Schindler's List      9          (1993)\n",
       "2                           12 Angry Men      9          (1957)\n",
       "3                        La vita è bella    8.6          (1997)\n",
       "4        Il buono, il brutto, il cattivo    8.8          (1966)\n",
       "5               The Shawshank Redemption    9.3          (1994)\n",
       "6               The Pursuit of Happyness      8          (2006)\n",
       "7                   Shichinin no samurai    8.6          (1954)\n",
       "8                       The Intouchables    8.5          (2011)\n",
       "9                      Central do Brasil      8          (1998)\n",
       "10                   Requiem for a Dream    8.3          (2000)\n",
       "11                      A Beautiful Mind    8.2          (2001)\n",
       "12                   Hachi: A Dog's Tale    8.1          (2009)\n",
       "13                                 Taken    7.8      (I) (2008)\n",
       "14                  Yeopgijeogin geunyeo      8          (2001)\n",
       "15                         Amores perros    8.1          (2000)\n",
       "16                           The Shining    8.4          (1980)\n",
       "17                            Apocalypto    7.8          (2006)\n",
       "18                             Gladiator    8.5          (2000)\n",
       "19                             Cast Away    7.8          (2000)\n",
       "20                       The Dark Knight      9          (2008)\n",
       "21                           The Pianist    8.5          (2002)\n",
       "22                               Titanic    7.9          (1997)\n",
       "23                               Bin-jip    7.9          (2004)\n",
       "24                            Braveheart    8.4          (1995)\n",
       "25                 It's a Wonderful Life    8.6          (1946)\n",
       "26  Bom yeoreum gaeul gyeoul geurigo bom      8          (2003)\n",
       "27                                 Alien    8.5          (1979)\n",
       "28                        Salinui chueok    8.1          (2003)\n",
       "29                        Vozvrashchenie    7.9          (2003)\n",
       "30                  Ang-ma-reul bo-at-da    7.8          (2010)\n",
       "31                     Bacheha-Ye aseman    8.2          (1997)\n",
       "32               Jodaeiye Nader az Simin    8.3          (2011)\n",
       "33                       The Sixth Sense    8.2          (1999)\n",
       "34               Nae meorisokui jiwoogae    8.1          (2004)\n",
       "35                             Okuribito      8          (2008)\n",
       "36                   Wo de fu qin mu qin    7.8          (1999)\n",
       "37                   Saving Private Ryan    8.6          (1998)\n",
       "38          The Bridge on the River Kwai    8.1          (1957)\n",
       "39                               Ben-Hur    8.1          (1959)\n",
       "40                          The Exorcist    8.1          (1973)\n",
       "41                El secreto de sus ojos    8.2          (2009)\n",
       "42                                  Léon    8.5          (1994)\n",
       "43                        The Green Mile    8.6          (1999)\n",
       "44                           Gran Torino    8.1          (2008)\n",
       "45                     Kill Bill: Vol. 1    8.2          (2003)\n",
       "46                         Jurassic Park    8.2          (1993)\n",
       "47            Terminator 2: Judgment Day    8.6          (1991)\n",
       "48                    Back to the Future    8.5          (1985)\n",
       "49                          Finding Nemo    8.2          (2003)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include libraries \n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#Send a request to the URL and get the HTML content\n",
    "webpage = requests.get('https://www.imdb.com/list/ls055386972/').content\n",
    "soup = BeautifulSoup(webpage, 'lxml')\n",
    "\n",
    "\n",
    "# Find all the movie titles, ratings and years of release\n",
    "name=[]\n",
    "rating=[]\n",
    "Year_of_release=[]\n",
    "\n",
    "movies = soup.find_all('div',class_='lister-item-content')\n",
    "\n",
    "for i in movies:\n",
    "    name.append(i.find('a').text)\n",
    "    rating.append(i.find('span', class_='ipl-rating-star__rating').text)\n",
    "    Year_of_release.append(i.find('span', class_='lister-item-year text-muted unbold').text)\n",
    "    \n",
    "    \n",
    "d = {'name':name, 'rating':rating,'Year_of_release':Year_of_release }    \n",
    "    \n",
    "df = pd.DataFrame(d)\n",
    "df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4033582e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f8b3685",
   "metadata": {},
   "source": [
    "Answer 3. IMDB Top 50 Indian Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dca757e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>Year_of_release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mohabbatein</td>\n",
       "      <td>7</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zindagi Na Milegi Dobara</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dil Chahta Hai</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bhaag Milkha Bhaag</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chak De! India</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lagaan: Once Upon a Time in India</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Wednesday</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jab We Met</td>\n",
       "      <td>7.9</td>\n",
       "      <td>(2007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Yeh Jawaani Hai Deewani</td>\n",
       "      <td>7.2</td>\n",
       "      <td>(2013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OMG: Oh My God!</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Raanjhanaa</td>\n",
       "      <td>7.6</td>\n",
       "      <td>(2013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Rockstar</td>\n",
       "      <td>7.7</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kal Ho Naa Ho</td>\n",
       "      <td>7.9</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vicky Donor</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Jaane Tu... Ya Jaane Na</td>\n",
       "      <td>7.4</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Udaan</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kabhi Khushi Kabhie Gham...</td>\n",
       "      <td>7.4</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Highway</td>\n",
       "      <td>7.6</td>\n",
       "      <td>(I) (2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Swades: We, the People</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Munna Bhai M.B.B.S.</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lage Raho Munna Bhai</td>\n",
       "      <td>8</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Golmaal: Fun Unlimited</td>\n",
       "      <td>7.4</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Delhi Belly</td>\n",
       "      <td>7.5</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Dhoom</td>\n",
       "      <td>6.6</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Raajneeti</td>\n",
       "      <td>7.1</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Gangs of Wasseypur</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Style</td>\n",
       "      <td>6.7</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Special Chabbis</td>\n",
       "      <td>8</td>\n",
       "      <td>(2013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dostana</td>\n",
       "      <td>6.5</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Namastey London</td>\n",
       "      <td>7.1</td>\n",
       "      <td>(2007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fashion</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>My Name Is Khan</td>\n",
       "      <td>7.9</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Wake Up Sid</td>\n",
       "      <td>7.6</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Rocket Singh: Salesman of the Year</td>\n",
       "      <td>7.5</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2 States</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Jodhaa Akbar</td>\n",
       "      <td>7.5</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ABCD (Any Body Can Dance)</td>\n",
       "      <td>6.3</td>\n",
       "      <td>(2013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Kaho Naa... Pyaar Hai</td>\n",
       "      <td>6.9</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name rating Year_of_release\n",
       "0                             3 Idiots    8.4          (2009)\n",
       "1                             Drishyam    8.2          (2015)\n",
       "2                          Mohabbatein      7          (2000)\n",
       "3             Zindagi Na Milegi Dobara    8.2          (2011)\n",
       "4                       Dil Chahta Hai    8.1          (2001)\n",
       "5                   Bhaag Milkha Bhaag    8.2          (2013)\n",
       "6                      Rang De Basanti    8.1          (2006)\n",
       "7                       Chak De! India    8.1          (2007)\n",
       "8    Lagaan: Once Upon a Time in India    8.1          (2001)\n",
       "9                          A Wednesday    8.1          (2008)\n",
       "10                          Jab We Met    7.9          (2007)\n",
       "11             Yeh Jawaani Hai Deewani    7.2          (2013)\n",
       "12                     OMG: Oh My God!    8.1          (2012)\n",
       "13                          Raanjhanaa    7.6          (2013)\n",
       "14                            Rockstar    7.7          (2011)\n",
       "15                       Kal Ho Naa Ho    7.9          (2003)\n",
       "16                         Vicky Donor    7.8          (2012)\n",
       "17             Jaane Tu... Ya Jaane Na    7.4          (2008)\n",
       "18                    Taare Zameen Par    8.3          (2007)\n",
       "19                               Udaan    8.1          (2010)\n",
       "20         Kabhi Khushi Kabhie Gham...    7.4          (2001)\n",
       "21                             Highway    7.6      (I) (2014)\n",
       "22              Swades: We, the People    8.2          (2004)\n",
       "23                 Munna Bhai M.B.B.S.    8.1          (2003)\n",
       "24                Lage Raho Munna Bhai      8          (2006)\n",
       "25              Golmaal: Fun Unlimited    7.4          (2006)\n",
       "26                         Delhi Belly    7.5          (2011)\n",
       "27                               Dhoom    6.6          (2004)\n",
       "28                           Raajneeti    7.1          (2010)\n",
       "29                  Gangs of Wasseypur    8.2          (2012)\n",
       "30                               Style    6.7          (2001)\n",
       "31                     Special Chabbis      8          (2013)\n",
       "32                             Dostana    6.5          (2008)\n",
       "33                     Namastey London    7.1          (2007)\n",
       "34                             Fashion    6.9          (2008)\n",
       "35                     My Name Is Khan    7.9          (2010)\n",
       "36                         Wake Up Sid    7.6          (2009)\n",
       "37  Rocket Singh: Salesman of the Year    7.5          (2009)\n",
       "38                            2 States    6.9          (2014)\n",
       "39                        Jodhaa Akbar    7.5          (2008)\n",
       "40           ABCD (Any Body Can Dance)    6.3          (2013)\n",
       "41               Kaho Naa... Pyaar Hai    6.9          (2000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "Webpage = requests.get('https://www.imdb.com/list/ls058711268/').content\n",
    "soup = BeautifulSoup(Webpage,'lxml')\n",
    "\n",
    "name=[]\n",
    "rating=[]\n",
    "Year_of_release=[]\n",
    "\n",
    "movies = soup.find_all('div',class_='lister-item-content')\n",
    "\n",
    "for i in movies:\n",
    "    name.append(i.find('a').text)\n",
    "    rating.append(i.find('span', class_='ipl-rating-star__rating').text)\n",
    "    Year_of_release.append(i.find('span', class_='lister-item-year text-muted unbold').text)\n",
    "    \n",
    "    \n",
    "d = {'name':name, 'rating':rating,'Year_of_release':Year_of_release }    \n",
    "    \n",
    "df = pd.DataFrame(d)\n",
    "df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f53221a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f67e914f",
   "metadata": {},
   "source": [
    "Answer 4. Presidents Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37240c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term_of_office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>[25 July, 2017, 25 July, 2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>[25 July, 2012, 25 July, 2017]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>[25 July, 2007, 25 July, 2012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>[25 July, 2002, 25 July, 2007]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>[25 July, 1997, 25 July, 2002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>[25 July, 1992, 25 July, 1997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>[25 July, 1987, 25 July, 1992]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>[25 July, 1982, 25 July, 1987]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>[25 July, 1977, 25 July, 1982]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>[24 August, 1974, 11 February, 1977]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>[3 May, 1969, 20 July, 1969, 24 August, 1969, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>[13 May, 1967, 3 May, 1969]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>[13 May, 1962, 13 May, 1967]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>[26 January, 1950, 13 May, 1962]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Name  \\\n",
       "0           Shri Ram Nath Kovind (birth - 1945)   \n",
       "1             Shri Pranab Mukherjee (1935-2020)   \n",
       "2   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "3            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "4            Shri K. R. Narayanan (1920 - 2005)   \n",
       "5           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "6               Shri R Venkataraman (1910-2009)   \n",
       "7                  Giani Zail Singh (1916-1994)   \n",
       "8         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "9          Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "10     Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "11                 Dr. Zakir Husain (1897-1969)   \n",
       "12     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "13             Dr. Rajendra Prasad (1884-1963)    \n",
       "\n",
       "                                       Term_of_office  \n",
       "0                      [25 July, 2017, 25 July, 2022]  \n",
       "1                      [25 July, 2012, 25 July, 2017]  \n",
       "2                      [25 July, 2007, 25 July, 2012]  \n",
       "3                      [25 July, 2002, 25 July, 2007]  \n",
       "4                      [25 July, 1997, 25 July, 2002]  \n",
       "5                      [25 July, 1992, 25 July, 1997]  \n",
       "6                      [25 July, 1987, 25 July, 1992]  \n",
       "7                      [25 July, 1982, 25 July, 1987]  \n",
       "8                      [25 July, 1977, 25 July, 1982]  \n",
       "9                [24 August, 1974, 11 February, 1977]  \n",
       "10  [3 May, 1969, 20 July, 1969, 24 August, 1969, ...  \n",
       "11                        [13 May, 1967, 3 May, 1969]  \n",
       "12                       [13 May, 1962, 13 May, 1967]  \n",
       "13                   [26 January, 1950, 13 May, 1962]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "url='https://presidentofindia.nic.in/former-presidents.htm'\n",
    "response= requests.get(url).content\n",
    "soup= BeautifulSoup(response,'lxml')\n",
    "\n",
    "data=soup.find_all('div',class_='presidentListing')\n",
    "\n",
    "Name=[]\n",
    "for i in data:\n",
    "    Name.append(i.find('h3').text)\n",
    "    \n",
    "Terms=[]\n",
    "for i in data:\n",
    "    Terms.append(i.find_all('p')[0].text)\n",
    "   \n",
    "\n",
    "pattern = r'\\d+\\s+\\w+,\\s+\\d+'\n",
    "Term_of_office=[]\n",
    "for term in Terms:\n",
    "    matches = re.findall(pattern, term)\n",
    "    if matches:\n",
    "        Term_of_office.append(matches)\n",
    "    else:\n",
    "        Term_of_office.append(\"No dates found.\")\n",
    "\n",
    "dic={'Name':Name,'Term_of_office':Term_of_office}\n",
    "df= pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044e5e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3083a120",
   "metadata": {},
   "source": [
    "Answer 5(a). Top 10 ODI Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c9d77d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 ODI teams \n",
      "   Position              Team Matches Points Rating\n",
      "0        1     Pakistan\\nPAK      29  3,291    113\n",
      "1        2    Australia\\nAUS      35  3,965    113\n",
      "2        3        India\\nIND      47  5,294    113\n",
      "3        4      England\\nENG      36  3,988    111\n",
      "4        5   New Zealand\\nNZ      35  3,740    107\n",
      "5        6  South Africa\\nSA      31  3,141    101\n",
      "6        7   Bangladesh\\nBAN      38  3,625     95\n",
      "7        8     Sri Lanka\\nSL      36  3,099     86\n",
      "8        9   West Indies\\nWI      43  3,105     72\n",
      "9       10  Afghanistan\\nAFG      20  1,419     71\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URLs for the rankings\n",
    "teams_url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "response = requests.get(teams_url)\n",
    "soup = BeautifulSoup( response.text ,'lxml')\n",
    "\n",
    "rows = soup.tbody.find_all('tr')\n",
    "\n",
    "data=[]\n",
    "for row in rows:\n",
    "    cells=row.find_all('td')\n",
    "    row_data=[]\n",
    "    for cell in cells:\n",
    "        row_data.append(cell.text.strip())\n",
    "    data.append(row_data)    \n",
    "    \n",
    "Team_df = pd.DataFrame(data[:10],columns=['Position','Team','Matches','Points','Rating'])\n",
    "print('\\n Top 10 ODI teams \\n',Team_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89379ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c65c36",
   "metadata": {},
   "source": [
    "Answer 5(b). Top 10 Men ODI Batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "553211c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Mens ODI Batsmen \n",
      "             Player_Names Team_Names Rating\n",
      "0             Babar Azam        PAK    887\n",
      "1           Fakhar Zaman        PAK    784\n",
      "2  Rassie van der Dussen         SA    777\n",
      "3           Shubman Gill        IND    738\n",
      "4            Imam-ul-Haq        PAK    737\n",
      "5           David Warner        AUS    726\n",
      "6            Virat Kohli        IND    719\n",
      "7        Quinton de Kock         SA    718\n",
      "8           Rohit Sharma        IND    707\n",
      "9            Steve Smith        AUS    702\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "table = soup.find('table',{'class':'table rankings-table'})\n",
    "\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "Player_names=[]\n",
    "Team_name=[]\n",
    "Rating=[]\n",
    "for row in rows[1:11]:\n",
    "    cells= row.find_all('td')\n",
    "    player = cells[1].text.strip()\n",
    "    Player_names.append(player)\n",
    "    team= cells[2].text.strip()\n",
    "    Team_name.append(team)\n",
    "    rating=cells[3].text.strip()\n",
    "    Rating.append(rating)\n",
    "    \n",
    "    \n",
    "df=pd.DataFrame({'Player_Names':Player_names,'Team_Names':Team_name,'Rating':Rating})\n",
    "print(\"\\n Top 10 Mens ODI Batsmen \\n\", df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d7feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "548000e4",
   "metadata": {},
   "source": [
    "Answer 5(c). Top 10 ODI Bowlers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9e9eb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10  ODI bowlers\n",
      "        Player_Names Team_Names Rating\n",
      "0    Josh Hazlewood        AUS    705\n",
      "1    Mohammed Siraj        IND    691\n",
      "2    Mitchell Starc        AUS    686\n",
      "3       Trent Boult         NZ    680\n",
      "4        Matt Henry         NZ    666\n",
      "5       Rashid Khan        AFG    659\n",
      "6        Adam Zampa        AUS    652\n",
      "7  Mujeeb Ur Rahman        AFG    637\n",
      "8   Shakib Al Hasan        BAN    636\n",
      "9    Shaheen Afridi        PAK    632\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "table = soup.find('table',{'class':'table rankings-table'})\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "Player_names=[]\n",
    "Team_name=[]\n",
    "Rating=[]\n",
    "for row in rows[1:11]:\n",
    "    cells= row.find_all('td')\n",
    "    player = cells[1].text.strip()\n",
    "    Player_names.append(player)\n",
    "    team= cells[2].text.strip()\n",
    "    Team_name.append(team)\n",
    "    rating=cells[3].text.strip()\n",
    "    Rating.append(rating)\n",
    "    \n",
    "    \n",
    "df=pd.DataFrame({'Player_Names':Player_names,'Team_Names':Team_name,'Rating':Rating})\n",
    "print('\\n Top 10  ODI bowlers\\n',df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa0ac30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3438db1c",
   "metadata": {},
   "source": [
    "Answer 6(a). Top 10 ODI Women Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de248b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 ODI teams \n",
      "   Position              Team Matches Points Rating\n",
      "0        1    Australia\\nAUS      21  3,603    172\n",
      "1        2      England\\nENG      28  3,342    119\n",
      "2        3  South Africa\\nSA      26  3,098    119\n",
      "3        4        India\\nIND      27  2,820    104\n",
      "4        5   New Zealand\\nNZ      25  2,553    102\n",
      "5        6   West Indies\\nWI      27  2,535     94\n",
      "6        7   Bangladesh\\nBAN      13    983     76\n",
      "7        8     Thailand\\nTHA      11    821     75\n",
      "8        9     Pakistan\\nPAK      27  1,678     62\n",
      "9       10     Sri Lanka\\nSL       8    353     44\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URLs for the rankings\n",
    "teams_url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "response = requests.get(teams_url)\n",
    "soup = BeautifulSoup( response.text ,'lxml')\n",
    "\n",
    "rows = soup.tbody.find_all('tr')\n",
    "\n",
    "data=[]\n",
    "for row in rows:\n",
    "    cells=row.find_all('td')\n",
    "    row_data=[]\n",
    "    for cell in cells:\n",
    "        row_data.append(cell.text.strip())\n",
    "    data.append(row_data)    \n",
    "    \n",
    "Team_df = pd.DataFrame(data[:10],columns=['Position','Team','Matches','Points','Rating'])\n",
    "print('\\n Top 10 ODI teams \\n',Team_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f58620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "562fb3d0",
   "metadata": {},
   "source": [
    "Answer 6(b). Top 10 ODI Batting Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa18a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Women ODI Batting \n",
      "           Player_Names Team_Names Rating\n",
      "0         Alyssa Healy        AUS    762\n",
      "1          Beth Mooney        AUS    754\n",
      "2      Laura Wolvaardt         SA    732\n",
      "3       Natalie Sciver        ENG    731\n",
      "4          Meg Lanning        AUS    717\n",
      "5     Harmanpreet Kaur        IND    716\n",
      "6      Smriti Mandhana        IND    714\n",
      "7  Chamari Athapaththu         SL    665\n",
      "8    Amy Satterthwaite         NZ    641\n",
      "9         Ellyse Perry        AUS    626\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "table = soup.find('table',{'class':'table rankings-table'})\n",
    "\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "Player_names=[]\n",
    "Team_name=[]\n",
    "Rating=[]\n",
    "for row in rows[1:11]:\n",
    "    cells= row.find_all('td')\n",
    "    player = cells[1].text.strip()\n",
    "    Player_names.append(player)\n",
    "    team= cells[2].text.strip()\n",
    "    Team_name.append(team)\n",
    "    rating=cells[3].text.strip()\n",
    "    Rating.append(rating)\n",
    "    \n",
    "    \n",
    "df=pd.DataFrame({'Player_Names':Player_names,'Team_Names':Team_name,'Rating':Rating})\n",
    "print(\"\\n Top 10 Women ODI Batting \\n\", df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc337c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e89838d0",
   "metadata": {},
   "source": [
    "Answer 6(c). Top 10 Women ODI All-Rounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0812cc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Womens ODI all-rounder\n",
      "         Player_Names Team_Names Rating\n",
      "0    Hayley Matthews         WI    373\n",
      "1     Natalie Sciver        ENG    371\n",
      "2       Ellyse Perry        AUS    366\n",
      "3     Marizanne Kapp         SA    349\n",
      "4        Amelia Kerr         NZ    336\n",
      "5      Deepti Sharma        IND    322\n",
      "6   Ashleigh Gardner        AUS    292\n",
      "7      Jess Jonassen        AUS    250\n",
      "8           Nida Dar        PAK    232\n",
      "9  Sophie Ecclestone        ENG    205\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "table = soup.find('table',{'class':'table rankings-table'})\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "Player_names=[]\n",
    "Team_name=[]\n",
    "Rating=[]\n",
    "for row in rows[1:11]:\n",
    "    cells= row.find_all('td')\n",
    "    player = cells[1].text.strip()\n",
    "    Player_names.append(player)\n",
    "    team= cells[2].text.strip()\n",
    "    Team_name.append(team)\n",
    "    rating=cells[3].text.strip()\n",
    "    Rating.append(rating)\n",
    "    \n",
    "    \n",
    "df=pd.DataFrame({'Player_Names':Player_names,'Team_Names':Team_name,'Rating':Rating})\n",
    "print('\\n Top 10 Womens ODI all-rounder\\n',df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71c2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4334bd33",
   "metadata": {},
   "source": [
    "Answer 7. Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18d8a593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News_Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warren Buffett says letting Silicon Valley Ban...</td>\n",
       "      <td>41 min ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/06/warren-buffett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dow jumps 500 points to break four-day losing ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/05/04/stock-market-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Berkshire operating earnings increase 12% in t...</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/06/berkshire-hath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buffett explains value investing: 'What gives ...</td>\n",
       "      <td>41 min ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/06/buffett-explai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Job growth totals 253,000 in April, beating ex...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/05/05/jobs-report-ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apple posts record quarter in India; analyst s...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/05/05/apple-posts-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What Chile's state-led lithium policy means fo...</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/06/chile-state-le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sudan on edge as warring parties to hold talks</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/05/06/sudan-on-edge-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Threat of TikTok ban has creators scrambling t...</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/06/threat-of-tikt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Here's where the U.S. jobs are for April 2023 ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/05/05/heres-where-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WHO declares end to Covid-19 global public hea...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/05/05/who-declares-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Scope Ratings places U.S. credit ratings under...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/05/06/scope-ratings-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SEC issues largest ever whistleblower award of...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/05/06/sec-issues-lar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ukraine downs Russian hypersonic missile with ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/05/06/ukraine-downs-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PacWest stock jumps 80% as regional banks rebo...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/05/05/regional-bank-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Warren Buffett's successor Greg Abel is wooing...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.cnbc.com/2023/05/05/warren-buffett...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline         Time  \\\n",
       "0   Warren Buffett says letting Silicon Valley Ban...   41 min ago   \n",
       "1   Dow jumps 500 points to break four-day losing ...         None   \n",
       "2                                                      4 hours ago   \n",
       "3   Berkshire operating earnings increase 12% in t...  4 hours ago   \n",
       "4   Buffett explains value investing: 'What gives ...   41 min ago   \n",
       "5   Job growth totals 253,000 in April, beating ex...         None   \n",
       "6   Apple posts record quarter in India; analyst s...         None   \n",
       "7   What Chile's state-led lithium policy means fo...  6 hours ago   \n",
       "8                                                             None   \n",
       "9     Sudan on edge as warring parties to hold talks          None   \n",
       "10  Threat of TikTok ban has creators scrambling t...  5 hours ago   \n",
       "11  Here's where the U.S. jobs are for April 2023 ...         None   \n",
       "12  WHO declares end to Covid-19 global public hea...         None   \n",
       "13  Scope Ratings places U.S. credit ratings under...         None   \n",
       "14  SEC issues largest ever whistleblower award of...         None   \n",
       "15  Ukraine downs Russian hypersonic missile with ...         None   \n",
       "16  PacWest stock jumps 80% as regional banks rebo...         None   \n",
       "17  Warren Buffett's successor Greg Abel is wooing...         None   \n",
       "\n",
       "                                            News_Link  \n",
       "0   https://www.cnbc.com/2023/05/06/warren-buffett...  \n",
       "1   https://www.cnbc.com/2023/05/04/stock-market-t...  \n",
       "2                                               /pro/  \n",
       "3   https://www.cnbc.com/2023/05/06/berkshire-hath...  \n",
       "4   https://www.cnbc.com/2023/05/06/buffett-explai...  \n",
       "5   https://www.cnbc.com/2023/05/05/jobs-report-ap...  \n",
       "6   https://www.cnbc.com/2023/05/05/apple-posts-re...  \n",
       "7   https://www.cnbc.com/2023/05/06/chile-state-le...  \n",
       "8                                               /pro/  \n",
       "9   https://www.cnbc.com/2023/05/06/sudan-on-edge-...  \n",
       "10  https://www.cnbc.com/2023/05/06/threat-of-tikt...  \n",
       "11  https://www.cnbc.com/2023/05/05/heres-where-th...  \n",
       "12  https://www.cnbc.com/2023/05/05/who-declares-e...  \n",
       "13  https://www.cnbc.com/2023/05/06/scope-ratings-...  \n",
       "14  https://www.cnbc.com/2023/05/06/sec-issues-lar...  \n",
       "15  https://www.cnbc.com/2023/05/06/ukraine-downs-...  \n",
       "16  https://www.cnbc.com/2023/05/05/regional-bank-...  \n",
       "17  https://www.cnbc.com/2023/05/05/warren-buffett...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URLs for the rankings\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "response = requests.get(url).content\n",
    "soup = BeautifulSoup( response ,'lxml')\n",
    "\n",
    "data=soup.find_all('div',class_='RiverPlusCard-cardLeft')\n",
    "\n",
    "Headline=[]\n",
    "for i in data:\n",
    "    Headline.append(i.find('a').text)\n",
    "    \n",
    "time=[]\n",
    "for i in data:\n",
    "    if i is not None:\n",
    "        time.append(i.find('span',class_='RiverByline-datePublished'))\n",
    "    else:\n",
    "        time.append(print('None'))\n",
    "         \n",
    "Time=[]\n",
    "for element in time:\n",
    "    if element is not None:\n",
    "        Time.append(element.text)\n",
    "    else:\n",
    "        Time.append(element)\n",
    "\n",
    "News_Link=[]\n",
    "for i in data:\n",
    "    News_Link.append(i.find('a')['href'])\n",
    "    \n",
    "dic={\"Headline\":Headline,\"Time\":Time,\"News_Link\":News_Link}\n",
    "df=pd.DataFrame(dic)\n",
    "df\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851aee2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0389d123",
   "metadata": {},
   "source": [
    "Answer 8. AI 90 Days Most Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ce7adfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper_Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published_date</th>\n",
       "      <th>Paper_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>David Silver, Satinder Singh, Doina Precup, Ri...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Margaret A. Boden</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Guni Sharon, Roni Stern, Ariel Felner, Nathan ...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "      <td>Ilaria Tiddi, Stefan Schlobach</td>\n",
       "      <td>January 2022</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Henry Prakken, Giovanni Sartor</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Kjersti Aas, Martin Jullum, Anders Løland</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Richard S. Sutton, Doina Precup, Satinder Singh</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>Jasper van der Waa, Elisabeth Nieuwburg, Anita...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Wenhan Luo, Junliang Xing and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Saurabh Arora, Prashant Doshi</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "      <td>Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz</td>\n",
       "      <td>November 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Nolan Bard, Jakob N. Foerster and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "      <td>Joe Collenette, Katie Atkinson, Trevor Bench-C...</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Séverin Lemaignan, Mathieu Warnier and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Ron Kohavi, George H. John</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Richard Evans, Matko Bošnjak and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "      <td>Markus Langer, Daniel Oster and 6 more</td>\n",
       "      <td>July 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "      <td>Oskar Wysocki, Jessica Katharine Davies and 5 ...</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "      <td>Luigia Carlucci Aiello</td>\n",
       "      <td>June 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Avrim L. Blum, Pat Langley</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "      <td>Leslie Pack Kaelbling, Michael L. Littman, Ant...</td>\n",
       "      <td>May 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper_Title  \\\n",
       "0                                    Reward is enough   \n",
       "1   Explanation in artificial intelligence: Insigh...   \n",
       "2              Creativity and artificial intelligence   \n",
       "3   Conflict-based search for optimal multi-agent ...   \n",
       "4   Knowledge graphs as tools for explainable mach...   \n",
       "5   Law and logic: A review from an argumentation ...   \n",
       "6   Explaining individual predictions when feature...   \n",
       "7   Between MDPs and semi-MDPs: A framework for te...   \n",
       "8   Evaluating XAI: A comparison of rule-based and...   \n",
       "9       Multiple object tracking: A literature review   \n",
       "10  A survey of inverse reinforcement learning: Ch...   \n",
       "11  Explaining black-box classifiers using post-ho...   \n",
       "12            Hard choices in artificial intelligence   \n",
       "13  The Hanabi challenge: A new frontier for AI re...   \n",
       "14  Explainable AI tools for legal reasoning about...   \n",
       "15  Artificial cognition for social human–robot in...   \n",
       "16              Wrappers for feature subset selection   \n",
       "17                          Making sense of raw input   \n",
       "18  What do we want from Explainable Artificial In...   \n",
       "19  Assessing the communication gap between AI mod...   \n",
       "20  The multifaceted impact of Ada Lovelace in the...   \n",
       "21  A review of possible effects of cognitive bias...   \n",
       "22  Selection of relevant features and examples in...   \n",
       "23  Planning and acting in partially observable st...   \n",
       "\n",
       "                                              Authors  Published_date  \\\n",
       "0   David Silver, Satinder Singh, Doina Precup, Ri...    October 2021   \n",
       "1                                         Tim Miller    February 2019   \n",
       "2                                  Margaret A. Boden      August 1998   \n",
       "3   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015   \n",
       "4                     Ilaria Tiddi, Stefan Schlobach     January 2022   \n",
       "5                     Henry Prakken, Giovanni Sartor     October 2015   \n",
       "6          Kjersti Aas, Martin Jullum, Anders Løland   September 2021   \n",
       "7    Richard S. Sutton, Doina Precup, Satinder Singh      August 1999   \n",
       "8   Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021   \n",
       "9                Wenhan Luo, Junliang Xing and 4 more      April 2021   \n",
       "10                     Saurabh Arora, Prashant Doshi      August 2021   \n",
       "11  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021   \n",
       "12  Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz    November 2021   \n",
       "13          Nolan Bard, Jakob N. Foerster and 13 more      March 2020   \n",
       "14  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023   \n",
       "15      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017   \n",
       "16                        Ron Kohavi, George H. John    December 1997   \n",
       "17            Richard Evans, Matko Bošnjak and 5 more    October 2021   \n",
       "18             Markus Langer, Daniel Oster and 6 more       July 2021   \n",
       "19  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023   \n",
       "20                            Luigia Carlucci Aiello        June 2016   \n",
       "21   Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz        June 2021   \n",
       "22                        Avrim L. Blum, Pat Langley    December 1997   \n",
       "23  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998   \n",
       "\n",
       "                                            Paper_url  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URLs for the rankings\n",
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "response = requests.get(url).content\n",
    "soup = BeautifulSoup( response ,'lxml')\n",
    "\n",
    "\n",
    "data=soup.find_all('article')\n",
    "\n",
    "Paper_title=[]\n",
    "for i in data:\n",
    "    Paper_title.append(i.find('h2').text)\n",
    "    \n",
    "Authors=[]\n",
    "for i in data:\n",
    "    Authors.append(i.find('span',class_='sc-1w3fpd7-0 dnCnAO').text)\n",
    "    \n",
    "Published_date=[]\n",
    "for i in data:\n",
    "    Published_date.append(i.find('span',class_='sc-1thf9ly-2 dvggWt').text)\n",
    "    \n",
    "Paper_url = []\n",
    "for i in data:\n",
    "    Paper_url.append(i.find('a')['href'])\n",
    "    \n",
    "dic = {'Paper_Title':Paper_title,'Authors':Authors,'Published_date':Published_date,'Paper_url':Paper_url}\n",
    "df=pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f149a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0f2bbeb",
   "metadata": {},
   "source": [
    "Answer 9. Dineout List of Hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "489ba34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resturant_Name</th>\n",
       "      <th>Cuisines</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Connaught Place</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3CS Mall,</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian</td>\n",
       "      <td>The Leela Ambience Convention Hotel,</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle's Barbeque.</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Pacific Mall,</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Gardens Galleria,</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Hilton Garden Inn,</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Suncity Business Tower,</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Resturant_Name      Cuisines  \\\n",
       "0                   Castle Barbeque       Chinese   \n",
       "1                   Jungle Jamboree  North Indian   \n",
       "2                        Cafe Knosh       Italian   \n",
       "3                Castle's Barbeque.       Chinese   \n",
       "4              The Barbeque Company  North Indian   \n",
       "5                       India Grill  North Indian   \n",
       "6                    Delhi Barbeque  North Indian   \n",
       "7  The Monarch - Bar Be Que Village  North Indian   \n",
       "8                 Indian Grill Room  North Indian   \n",
       "\n",
       "                               Location Rating  \\\n",
       "0                       Connaught Place      4   \n",
       "1                             3CS Mall,    3.9   \n",
       "2  The Leela Ambience Convention Hotel,    4.3   \n",
       "3                         Pacific Mall,    3.9   \n",
       "4                     Gardens Galleria,    3.9   \n",
       "5                    Hilton Garden Inn,    3.9   \n",
       "6               Taurus Sarovar Portico,    3.7   \n",
       "7           Indirapuram Habitat Centre,    3.8   \n",
       "8               Suncity Business Tower,    4.3   \n",
       "\n",
       "                                           Image_url  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URLs for the rankings\n",
    "url = 'https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "webpage = requests.get(url).content\n",
    "soup = BeautifulSoup( webpage ,'lxml')\n",
    "\n",
    "\n",
    "Resturant=soup.find_all('div', class_='restnt-main-wrap clearfix')\n",
    "\n",
    "Resturant_Name = []\n",
    "for i in Resturant:\n",
    "        Resturant_Name.append(i.find('a').text)\n",
    "\n",
    "cuisines = soup.find_all('span',{'class':'double-line-ellipsis'})\n",
    "\n",
    "Cuisines=[]\n",
    "for i in cuisines:\n",
    "    Cuisines.append(i.find('a').text)\n",
    "                        \n",
    "location = soup.find_all('div',class_='restnt-loc ellipsis')\n",
    "                        \n",
    "Location = []\n",
    "for i in location:\n",
    "    Location.append(i.find('a').text)\n",
    "                        \n",
    "rating = soup.find_all('div', class_='restnt-rating rating-4')\n",
    "                        \n",
    "Rating =[]\n",
    "for i in rating:\n",
    "    Rating.append(i.text)\n",
    "                        \n",
    "image = soup.find_all('img', class_='no-img')\n",
    "                        \n",
    "Image_url = []\n",
    "for i in image:\n",
    "    Image_url.append(i['data-src'])\n",
    "                        \n",
    "dicto={\"Resturant_Name\":Resturant_Name,\"Cuisines\":Cuisines,\"Location\":Location,\"Rating\":Rating,\"Image_url\":Image_url}\n",
    "df=pd.DataFrame(dicto)\n",
    "df                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c733baa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
