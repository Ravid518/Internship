{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd42f773",
   "metadata": {},
   "source": [
    "# Assignment Solutions-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6604b",
   "metadata": {},
   "source": [
    "A-1. First 10  Data Analyst job list in Bangalore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "SearchDesignation = driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "SearchDesignation.send_keys('Data Analyst')\n",
    "\n",
    "SearchLocation = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "SearchLocation.send_keys('Bangalore')\n",
    "    \n",
    "SearchButton = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[6]') \n",
    "SearchButton.click()\n",
    "\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(2)\n",
    "\n",
    "# create a empty lists\n",
    "Job_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_Required=[]\n",
    "\n",
    "# Find all the job listings on the page\n",
    "job_listings = driver.find_elements(By.XPATH,'//div[@class=\"jobTupleHeader\"]')\n",
    "\n",
    "# Extract the company title name for each job listing\n",
    "for job in job_listings[:10]:\n",
    "    Job_title = job.find_element(By.XPATH,'.//a[@class=\"title ellipsis\"]')\n",
    "    Job_location=job.find_element(By.XPATH,'.//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "    Company_name=job.find_element(By.XPATH,'.//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "    Experience_required=job.find_element(By.XPATH,'.//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "    \n",
    "    Job_Title.append(Job_title.text)\n",
    "    Job_Location.append(Job_location.text)\n",
    "    Company_Name.append(Company_name.text)\n",
    "    Experience_Required.append(Experience_required.text)\n",
    "    \n",
    "# Create a dataframe\n",
    "dic={'Job_Title':Job_Title,'Job_Location':Job_Location,'Company_Name':Company_Name,'Experience_Required':Experience_Required}\n",
    "\n",
    "df = pd.DataFrame(dic)\n",
    "df\n",
    "\n",
    "# Close the web driver\n",
    "driver.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200bf8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dcf6e6",
   "metadata": {},
   "source": [
    "A-2. Search First 10 Job list for Data Scientist  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73d9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include libraries \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the web driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "SearchDesignation = driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "SearchDesignation.send_keys('Data Scientist')\n",
    "\n",
    "SearchLocation = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "SearchLocation.send_keys('Bangalore')\n",
    "    \n",
    "SearchButton = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[6]') \n",
    "SearchButton.click()\n",
    "\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(2)\n",
    "\n",
    "# create a empty lists\n",
    "Job_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_Required=[]\n",
    "\n",
    "# Find all the job listings on the page\n",
    "job_listings = driver.find_elements(By.XPATH,'//div[@class=\"jobTupleHeader\"]')\n",
    "\n",
    "# Extract the company title name for each job listing\n",
    "for job in job_listings[:10]:\n",
    "    Job_title = job.find_element(By.XPATH,'.//a[@class=\"title ellipsis\"]')\n",
    "    Job_location=job.find_element(By.XPATH,'.//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "    Company_name=job.find_element(By.XPATH,'.//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "    Experience_required=job.find_element(By.XPATH,'.//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "    \n",
    "    Job_Title.append(Job_title.text)\n",
    "    Job_Location.append(Job_location.text)\n",
    "    Company_Name.append(Company_name.text)\n",
    "    Experience_Required.append(Experience_required.text)\n",
    "    \n",
    "# Create a dataframe\n",
    "dic={'Job_Title':Job_Title,'Job_Location':Job_Location,'Company_Name':Company_Name,'Experience_Required':Experience_Required}\n",
    "\n",
    "df = pd.DataFrame(dic)\n",
    "df\n",
    "\n",
    "# Close the web driver\n",
    "driver.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1815fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d986bfd",
   "metadata": {},
   "source": [
    "A-3 First 10 job search using filter salary and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include liabraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# set up the driver \n",
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "Search_Designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "Search_Designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "Search_button = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[6]')\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using filter tick mark\n",
    "loc_filter =driver.find_elements(By.XPATH,\"//div[@class='chckBoxCont mt-8']//span\")\n",
    "for i in loc_filter :\n",
    "    if (i.text=='Delhi / NCR'):\n",
    "        i.click()\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7069fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using filter tick mark\n",
    "sal_filter =driver.find_elements(By.XPATH,\"//div[@class='chckBoxCont mt-8']//span\")\n",
    "for i in sal_filter :\n",
    "    if (i.text=='3-6 Lakhs'):\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "\n",
    "# create a empty lists\n",
    "Job_Title=[]\n",
    "Job_Location=[]\n",
    "Company_Name=[]\n",
    "Experience_Required=[]\n",
    "\n",
    "# Find all the job listings on the page\n",
    "job_listings = driver.find_elements(By.XPATH,'//div[@class=\"jobTupleHeader\"]')\n",
    "\n",
    "# Extract the company title name for each job listing\n",
    "for job in job_listings[:10]:\n",
    "    Job_title = job.find_element(By.XPATH,'.//a[@class=\"title ellipsis\"]')\n",
    "    Job_location=job.find_element(By.XPATH,'.//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "    Company_name=job.find_element(By.XPATH,'.//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "    Experience_required=job.find_element(By.XPATH,'.//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "    \n",
    "    Job_Title.append(Job_title.text)\n",
    "    Job_Location.append(Job_location.text)\n",
    "    Company_Name.append(Company_name.text)\n",
    "    Experience_Required.append(Experience_required.text)\n",
    "    \n",
    "# Create a dataframe\n",
    "dic={'Job_Title':Job_Title,'Job_Location':Job_Location,'Company_Name':Company_Name,'Experience_Required':Experience_Required}\n",
    "\n",
    "df = pd.DataFrame(dic)\n",
    "df\n",
    "\n",
    "# Close the web driver\n",
    "driver.close()\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92492224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a24323",
   "metadata": {},
   "source": [
    "A-4 Scrape data for first 100 Sunglasses in filpkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ac919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import selenium\n",
    "\n",
    "#Search a website\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.flipkart.com/')\n",
    "driver.maximize_window()\n",
    "\n",
    "Button= driver.find_element(By.XPATH,\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "Button.click()\n",
    "Search_data = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "Search_data.send_keys(\"Sunglasses\")\n",
    "Submit = driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")\n",
    "Submit.click()\n",
    "\n",
    "# Create a  column class\n",
    "def Brand_data():\n",
    "    Brand=[]\n",
    "    brand = driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    time.sleep(3)\n",
    "    for i in brand:\n",
    "        try:\n",
    "            Brand.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "               Brand.append('--') \n",
    "    return Brand                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Product_des_data():\n",
    "    Product_description=[]\n",
    "    product=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa' or @class='IRpwTa _2-ICcC']\")\n",
    "    print(len(product))\n",
    "    time.sleep(3)\n",
    "    for i in product:\n",
    "        try:\n",
    "            Product_description.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            Product_description.append(\"--\")\n",
    "    return Product_description\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f141b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "def Price_data():\n",
    "    Price=[]\n",
    "    price=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    time.sleep(3)\n",
    "    for i in price:\n",
    "        try:\n",
    "            Price.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            Price.append(\"--\")\n",
    "            \n",
    "    return Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "Product_description=[]\n",
    "Price=[]\n",
    "length=len(Brand)\n",
    "while(length<=100):\n",
    "    driver.refresh()\n",
    "    Brand.extend(Brand_data())\n",
    "    Product_description.extend(Product_des_data())\n",
    "    Price.extend(Price_data())\n",
    "    time.sleep(3)\n",
    "    next_btn=driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']/span\")\n",
    "    next_btn.click()\n",
    "    length=len(Brand)\n",
    "len(Price)\n",
    "\n",
    "#inspecting the length of scraped attributes\n",
    "length_list=[len(Brand),len(Product_description),len(Price)]\n",
    "length_list\n",
    "\n",
    "#creating DataFrame for the scraped data\n",
    "import pandas as pd\n",
    "Sunglasses=pd.DataFrame()\n",
    "Sunglasses[\"INDEX\"]=range(1,101)\n",
    "Sunglasses[\"BRAND\"]=Brand[:100]\n",
    "Sunglasses[\"PRODUCT_DESCRIPTION\"]=Product_description[:100]\n",
    "Sunglasses[\"PRICE\"]=Price[:100]\n",
    "Sunglasses.set_index(\"INDEX\",inplace=True)\n",
    "Sunglasses\n",
    "\n",
    "# close the web page\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d486bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b73c67ef",
   "metadata": {},
   "source": [
    "A-5 Scrape 100 reviews data from flipkart.com for iphone11 phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e8cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include add libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import selenium\n",
    "\n",
    "#Search a website and set up driver\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-white-128-gb/product-reviews/itme32df47ea6742?pid=MOBFWQ6B7KKRXDDS&lid=LSTMOBFWQ6B7KKRXDDSULUZ0N&marketplace=FLIPKART')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46da50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function for text extract\n",
    "def Rating_data():\n",
    "    \n",
    "    Ration=[]\n",
    "    rating= driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    for i in rating:\n",
    "        \n",
    "        try:\n",
    "            Rating.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "           \n",
    "        except:\n",
    "            Rating.append(\"--\")\n",
    "    return Rating       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b64ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function for text extract\n",
    "def Review_data():\n",
    "    \n",
    "    Review=[]\n",
    "    review= driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "    for i in review:\n",
    "        \n",
    "        try:\n",
    "            Review.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "           \n",
    "        except:\n",
    "            Review.append(\"--\")\n",
    "    return Review       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function for text extract\n",
    "def Full_review_data():\n",
    "    \n",
    "    Full_review=[]\n",
    "    full_review= driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "    for i in full_review:\n",
    "        \n",
    "        try:\n",
    "            Full_review.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "           \n",
    "        except:\n",
    "            Full_review.append(\"--\")\n",
    "    return Full_review       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d9d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a empty list\n",
    "Rating=[]\n",
    "Review=[]\n",
    "Full_review=[]\n",
    "\n",
    "# Create loop to extract data for next pages\n",
    "length =len(Rating)\n",
    "while(length<=100):\n",
    "    driver.refresh()\n",
    "    Rating.extend(Rating_data())\n",
    "    time.sleep(3)\n",
    "    next_btn=driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']/span\")\n",
    "    next_btn.click()\n",
    "    length=len(Rating)\n",
    "len(Rating)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1eff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loop to extract data for next pages\n",
    "length =len(Review)\n",
    "while(length<=100):\n",
    "    driver.refresh()\n",
    "    Review.extend(Review_data())\n",
    "    next_btn=driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']/span\")\n",
    "    next_btn.click()\n",
    "    length=len(Review)\n",
    "\n",
    "len(Review)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e7c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loop to extract data for next pages\n",
    "length = len(Full_review)\n",
    "while(length<=100):\n",
    "    driver.refresh()\n",
    "    Full_review.extend(Full_review_data())\n",
    "    next_btn=driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']/span\")\n",
    "    next_btn.click()\n",
    "    length=len(Full_review)\n",
    "len(Full_review)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c152f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list=[len(Rating),len(Review),len(Full_review)]\n",
    "length_list\n",
    "\n",
    "# Create a DataFrame\n",
    "Apple_phone=pd.DataFrame()\n",
    "Apple_phone[\"INDEX\"]=range(1,101)\n",
    "Apple_phone[\"Rating\"]=Rating[:100]\n",
    "Apple_phone[\"Review\"]=Review[:100]\n",
    "Apple_phone[\"Full_review\"]=Full_review[:100]\n",
    "Apple_phone.set_index(\"INDEX\",inplace=True)\n",
    "Apple_phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b699d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec3378b3",
   "metadata": {},
   "source": [
    "A-6 Scrape data for first 100 sneakers you find when you visit flipkart.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c4c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "# set up the driver in web pages\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('http://www.flipkart.com/')\n",
    "close_tabs = driver.find_element(By.XPATH,\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "close_tabs.click()\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "Search_text= driver.find_element(By.XPATH,\"//input[@class='_3704LK']\")\n",
    "Search_text.send_keys('Sneakers')\n",
    "Search_button = driver.find_element(By.XPATH,\"//button[@class= 'L0Z3Pu']\")\n",
    "Search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ff048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to extract text data list\n",
    "def Brand_data():\n",
    "    Brand=[]\n",
    "    brand = driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    time.sleep(3)\n",
    "    for i in brand:\n",
    "        try:\n",
    "            Brand.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "               Brand.append('--') \n",
    "    return Brand                \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to extract text data list\n",
    "def Product_data():\n",
    "    Product_description=[]\n",
    "    product=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa' or @class='IRpwTa _2-ICcC']\")\n",
    "    print(len(product))\n",
    "    time.sleep(3)\n",
    "    for i in product:\n",
    "        try:\n",
    "            Product_description.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            Product_description.append(\"--\")\n",
    "    return Product_description\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e22d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to extract text data list            \n",
    "def Price_data():\n",
    "    Price=[]\n",
    "    price=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    time.sleep(3)\n",
    "    for i in price:\n",
    "        try:\n",
    "            Price.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            Price.append(\"--\")\n",
    "            \n",
    "    return Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21bd3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a empty list  \n",
    "Brand=[]\n",
    "Product_description=[]\n",
    "Price=[]\n",
    "\n",
    "# loop for extract next page data\n",
    "length=len(Brand)\n",
    "while(length<=100):\n",
    "    driver.refresh()\n",
    "    Brand.extend(Brand_data())\n",
    "    Product_description.extend(Product_data())\n",
    "    Price.extend(Price_data())\n",
    "    time.sleep(3)\n",
    "    next_btn=driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']/span\")\n",
    "    next_btn.click()\n",
    "    length=len(Brand)\n",
    "len(Price)\n",
    "\n",
    "#inspecting the length of scraped attributes\n",
    "length_list=[len(Brand),len(Product_description),len(Price)]\n",
    "length_list\n",
    "\n",
    "#creating DataFrame for the scraped data\n",
    "import pandas as pd\n",
    "Sneakers=pd.DataFrame()\n",
    "Sneakers[\"INDEX\"]=range(1,101)\n",
    "Sneakers[\"BRAND\"]=Brand[:100]\n",
    "Sneakers[\"PRODUCT_DESCRIPTION\"]=Product_description[:100]\n",
    "Sneakers[\"PRICE\"]=Price[:100]\n",
    "Sneakers.set_index(\"INDEX\",inplace=True)\n",
    "Sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b8970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5ff5ea8",
   "metadata": {},
   "source": [
    "A-7 Scrape data first 10 search Intel i7 laptop in amazon web site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32461c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "# Set \n",
    "driver = webdriver.Chrome('chromedriver.exe') \n",
    "driver.get('https://www.amazon.in/')\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "Search_text=driver.find_element(By.XPATH,\"//input[@type='text']\")\n",
    "Search_text.send_keys('Laptop')\n",
    "Search_btn=driver.find_element(By.XPATH,\"//input[@id='nav-search-submit-button']\")\n",
    "Search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7530dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters= driver.find_elements(By.XPATH,\"//span[@class='a-size-base a-color-base']\")\n",
    "for i in Filters:\n",
    "    if(i.text== 'Intel Core i7'):\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610e10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a empty list  \n",
    "Title=[]\n",
    "Ratings=[]\n",
    "Price=[]\n",
    "\n",
    "# Find all the laptop in the page\n",
    "Laptop_list = driver.find_elements(By.XPATH,\"//div[@class='a-section a-spacing-small a-spacing-top-small']\")\n",
    "\n",
    "for i in Laptop_list[:10]:\n",
    "    title=i.find_element(By.XPATH,\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "    ratings = i.find_element(By.XPATH,\"//span[@class='a-icon-alt']/..\")\n",
    "    ratings = ratings.get_attribute('innerHTML').split(\">\")[1].split(\" \")[0]        \n",
    "    \n",
    "    price=i.find_element(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "    \n",
    "    Title.append(title.text)\n",
    "    Ratings.append(ratings)\n",
    "    Price.append(price.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d9f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe\n",
    "dic={'Title':Title,'Ratings':Ratings,'Price':Price}\n",
    "df = pd.DataFrame(dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e208f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a15c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4937e50a",
   "metadata": {},
   "source": [
    "A-8 Scrape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c935fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe') \n",
    "driver.get('https://www.azquotes.com/')\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "Search_btn=driver.find_element(By.LINK_TEXT,\"TOP QUOTES\")\n",
    "Search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85e1262",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quotes_list = driver.find_elements(By.CLASS_NAME,\"wrap-block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quotes=[]\n",
    "Authors=[]\n",
    "Type_quotes=[]\n",
    "\n",
    "Quotes_list = driver.find_elements(By.CLASS_NAME,\"wrap-block\")\n",
    "for i in Quotes_list:\n",
    "    quotes=i.find_element(By.CLASS_NAME,\"title\")\n",
    "    authors=i.find_element(By.CLASS_NAME,\"author\")\n",
    "    type_quotes=i.find_element(By.CLASS_NAME,\"tags\")\n",
    "    \n",
    "    Quotes.append(quotes.text)\n",
    "    Authors.append(authors.text)\n",
    "    Type_quotes.append(type_quotes.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d186d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={\"Quotes\":Quotes,\"Authors\":Authors,\"Type_quotes\":Type_quotes}\n",
    "df=pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e00891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa8cfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f3e44b7",
   "metadata": {},
   "source": [
    "A-9 Scrape data list of respected former Prime Ministers of India in https://www.jagranjosh.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e296cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe') \n",
    "driver.get('https://www.jagranjosh.com/')\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "Click_btn=driver.find_element(By.LINK_TEXT,\"GK\")\n",
    "Click_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e82a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "Click_btn2=driver.find_element(By.XPATH,'//a[text()=\"List of Prime Ministers of India \"]')\n",
    "Click_btn2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fa73bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=driver.find_element(By.XPATH,\"//table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "rows=table.find_elements(By.TAG_NAME,\"tr\")\n",
    "for row in rows:\n",
    "    cells=row.find_elements(By.TAG_NAME,'td')\n",
    "    row_data=[]\n",
    "    for cell in cells:\n",
    "        row_data.append(cell.text)\n",
    "    data.append(row_data)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b067dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prime_Ministers = pd.DataFrame(data,columns =['S.N','Name','Born-Dead','Term of office','Remark'])\n",
    "Prime_Ministers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22465023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940bceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe') \n",
    "driver.get('https://www.motor1.com/')\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "Click_btn=driver.find_element(By.LINK_TEXT,\"FEATURES\")\n",
    "Click_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a15b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "Click_btn=driver.find_element(By.XPATH,\"//div[@class='moreContent content-center']\")\n",
    "Click_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82880e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "element= driver.find_elements(By.TAG_NAME,\"h3\")\n",
    "for i in element:\n",
    "    if(i.text==\"50 Most Expensive Cars In The World\"):\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e0ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Car_name=[]\n",
    "car_list = driver.find_elements(By.TAG_NAME,\"h3\")\n",
    "for i in car_list:\n",
    "    try:\n",
    "        Car_name.append(i.text)\n",
    "    except:\n",
    "        Car_name.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fc21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Car_price =[]\n",
    "price_list = driver.find_elements(By.TAG_NAME,\"strong\")\n",
    "for i in price_list:\n",
    "    try:\n",
    "        Car_price.append(i.text)\n",
    "    except:\n",
    "        Car_price.append('__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Car_name':Car_name[:50],'Car_price':Car_price[:50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed707ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0cf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
